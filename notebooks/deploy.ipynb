{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "import umap.umap_ as umap\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_snake(text: list[str]) -> list[str]:    \n",
    "    '''\n",
    "    Converts given text to snake_case.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : list[str]\n",
    "    Text to be converted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : list[str]\n",
    "    New text in snake_case.\n",
    "    '''  \n",
    "    text = re.sub(r'(?<!^)(?=[A-Z])', '_', text).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. **Collecting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = 'C:/Users/bruno/OneDrive/Documentos/repos/ds-em-clusterizacao'\n",
    "df_raw = pd.read_csv(path + '/data/ecommerce.csv', encoding='cp1252')\n",
    "\n",
    "# Drop extra column\n",
    "df_raw.drop(columns=['Unnamed: 8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Data Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. **Renaming Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original columns\n",
    "cols = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
    "       'UnitPrice', 'CustomerID', 'Country']\n",
    "\n",
    "# Applying to_snake function\n",
    "snake = lambda x: to_snake(x) \n",
    "new_cols = list(map(snake, cols))\n",
    "\n",
    "# Renaming\n",
    "df2.columns = new_cols\n",
    "\n",
    "# customer_i_d to customer_id\n",
    "df2.rename(columns={'customer_i_d':'customer_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. **Treating NA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df2.loc[df2['customer_id'].isna(), :] # purchases with missing values on customer_id\n",
    "df_not_missing = df2.loc[~df2['customer_id'].isna(), :] # purchases without missing values on customer_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a reference table -> df_backup\n",
    "start_id = df2['customer_id'].max() + 1 # first new customer_id = 18288\n",
    "df_backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates()) # all unique invoice_no in df_missing\n",
    "df_backup['customer_id'] = np.arange(start_id, start_id + len(df_backup), 1)\n",
    "\n",
    "# Merging df_backup on df2\n",
    "df2 = pd.merge(df2, df_backup, on='invoice_no', how='left')\n",
    "df2['customer_id'] = df2['customer_id_x'].combine_first(df2['customer_id_y'])\n",
    "\n",
    "# Dropping auxiliary columns\n",
    "df2 = df2.drop(columns=['customer_id_x', 'customer_id_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. **Changing Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice_date\n",
    "df2['invoice_date'] = pd.to_datetime(df2['invoice_date'], format='%d-%b-%y')\n",
    "\n",
    "# customer_id\n",
    "df2['customer_id'] = df2['customer_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Feature Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit_price\n",
    "df3 = df3.loc[df3['unit_price'] > 0.01, :] # removing all negative prices (there're some prices with values such as 0.0001 im them, hence the > 0.01)\n",
    "\n",
    "# stock_code\n",
    "df3 = df3[~df3['stock_code'].isin(['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL', 'PADS', 'B', 'CRUK', 'C2'])] # removing stock codes that aren't actual products\n",
    "\n",
    "# description and country\n",
    "df3 = df3.drop(columns=['description', 'country']) # dropping description and countries, as those aren't relevant when modelling\n",
    "\n",
    "# bad users\n",
    "bad_users = [13672, 12346, 13762, 18268, 14557, 16878, 13364, \n",
    "             14792, 12607, 12454,18274, 12558, 16446, 17548, \n",
    "             16546, 15823]\n",
    "df3 = df3[~df3['customer_id'].isin(bad_users)] # removing bad users\n",
    "\n",
    "# quantity\n",
    "df_returns = df3.loc[df3['quantity'] < 0, :] # negative quantities - returns\n",
    "df_purchase = df3.loc[df3['quantity'] >= 0, :] # positive quantities - actual purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# Data reference - created so that we can add features on it latter\n",
    "df_ref = df4[['customer_id']].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. **Creating Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.1. **Gross Revenue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross revenue for each customer, which is equal to quantity times unit price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross Revenue \n",
    "df_purchase = df_purchase.assign(gross_revenue=df_purchase['quantity']*df_purchase['unit_price'])\n",
    "df_monetary = df_purchase[['gross_revenue','customer_id']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on='customer_id', how='left') # merging gross_revenue into df_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.2. **Recency - Day from last purchase**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period of time from current time to the last purchase. \n",
    "\n",
    "*current time is considered as the last day available in the dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency\n",
    "df_recency = df_purchase[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index() # last purchase date for each customer\n",
    "df_recency['recency_days'] = (df_purchase['invoice_date'].max() - df_recency['invoice_date']).dt.days # getting the recency\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge(df_ref, df_recency, on='customer_id', how='left') # merging recency_days into df_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.3. **Purchases Quantity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of times a person's made any purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchases Quantity\n",
    "df_purchases_quantity = df_purchase[['invoice_no','customer_id']].drop_duplicates().groupby('customer_id').count().reset_index().rename(columns={'invoice_no':'purchases_quantity'})\n",
    "df_ref = pd.merge(df_ref, df_purchases_quantity, on='customer_id', how='left') # merging purchases quantity into df_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.4. **Quantity of Items**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total quantity of items purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantity of Items\n",
    "df_quantity = df_purchase[['quantity','customer_id']].groupby('customer_id').sum().reset_index().rename(columns={'quantity':'qt_items'})\n",
    "df_ref = pd.merge(df_ref, df_quantity, on='customer_id', how='left') # merging qt_items into df_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.8. **Returns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of products quantities returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns\n",
    "df_returns = df_returns[['customer_id', 'quantity']].groupby('customer_id').sum().reset_index().rename(columns={'quantity':'qt_returns'}) # counting the amount of products returned\n",
    "df_returns['qt_returns'] = df_returns['qt_returns']*-1 # setting quantity values to positive\n",
    "df_ref = pd.merge(df_ref, df_returns, on='customer_id', how='left') # merging returns into df_ref\n",
    "df_ref.loc[df_ref['qt_returns'].isna(), 'qt_returns'] = 0 # replacing NA returns with 0, which means a customer has never made a return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.9. **purchased_returned_diff**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural log of difference between purchases and returns: \n",
    "\n",
    "$purchased\\_returned\\_diff = \\ln\\left({\\dfrac{quantity\\_of\\_items}{qt\\_returns}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of difference between purchases and returns\n",
    "df_ref['purchased_returned_diff'] = np.log(df_ref['qt_items'] - df_ref['qt_returns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df_ref.dropna().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "df6['gross_revenue'] = mm.fit_transform(df6[['gross_revenue']])\n",
    "df6['recency_days'] = mm.fit_transform(df6[['recency_days']])\n",
    "df6['purchases_quantity'] = mm.fit_transform(df6[['purchases_quantity']])\n",
    "df6['qt_returns'] = mm.fit_transform(df6[['qt_returns']])\n",
    "df6['qt_items'] = mm.fit_transform(df6[['qt_items']])\n",
    "df6['purchased_returned_diff'] = mm.fit_transform(df6[['purchased_returned_diff']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. **Space Analysis and Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df6.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3. **Tree-Based Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "X = df8.drop(columns=['customer_id', 'gross_revenue'])\n",
    "y = df8['gross_revenue'].copy()\n",
    "\n",
    "# Model Definition\n",
    "rf_model = RandomForestRegressor(n_estimators=100, \n",
    "                                 min_samples_split=32,                                 \n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=42)\n",
    "# Model Training\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# DataFrame Leaf\n",
    "df_leaf = pd.DataFrame(rf_model.apply(X)) # Apply trees in the forest to X, return leaf indices.     \n",
    "\n",
    "# Reducing Dimensionality\n",
    "reducer = umap.UMAP(n_neighbors=200, \n",
    "                    random_state=42, \n",
    "                    metric='manhattan', \n",
    "                    n_epochs=450)\n",
    "\n",
    "embedding = reducer.fit_transform(df_leaf) # reducing dimensionality to 2d     \n",
    "df_tree = pd.DataFrame()\n",
    "\n",
    "# Embedding\n",
    "df_tree['embedding_x'] = embedding[:, 0] # x component\n",
    "df_tree['embedding_y'] = embedding[:, 1] # y component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling df_tree\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "df_tree['embedding_x'] = mm.fit_transform(df_tree[['embedding_x']])\n",
    "df_tree['embedding_y'] = mm.fit_transform(df_tree[['embedding_y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_x</th>\n",
       "      <th>embedding_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954408</td>\n",
       "      <td>0.203594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944175</td>\n",
       "      <td>0.241854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.762645</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.629727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300886</td>\n",
       "      <td>0.756669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>0.922310</td>\n",
       "      <td>0.323514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>0.960786</td>\n",
       "      <td>0.224433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>0.660737</td>\n",
       "      <td>0.377764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.374229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0.969744</td>\n",
       "      <td>0.814752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      embedding_x  embedding_y\n",
       "0        0.954408     0.203594\n",
       "1        0.944175     0.241854\n",
       "2        0.762645     0.015281\n",
       "3        0.785903     0.629727\n",
       "4        0.300886     0.756669\n",
       "...           ...          ...\n",
       "5685     0.922310     0.323514\n",
       "5686     0.960786     0.224433\n",
       "5687     0.660737     0.377764\n",
       "5688     0.671971     0.374229\n",
       "5689     0.969744     0.814752\n",
       "\n",
       "[5690 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. **Machine Learning Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "X = df_tree.copy()\n",
    "\n",
    "# Defining the model\n",
    "kmeans_model = KMeans(n_clusters=8, random_state=42)  # 8 to 11 provides good results\n",
    "\n",
    "# Training the model\n",
    "kmeans_model.fit(X)\n",
    "\n",
    "# Predict\n",
    "kmeans_labels = kmeans_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. **Final DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df5.copy()\n",
    "df_final['cluster'] = kmeans_labels\n",
    "df_final['cluster'] = df_final['cluster'].apply(lambda x: 'insiders' if x == 0\n",
    "                                                            else 'runners_up' if x == 5 \n",
    "                                                            else 'promising' if x == 6 \n",
    "                                                            else 'potentials' if x == 1 \n",
    "                                                            else 'need_attention' if x == 7 \n",
    "                                                            else 'about_to_sleep' if x == 4 \n",
    "                                                            else 'at_risk' if x == 3\n",
    "                                                            else 'about_to_lose')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing dtypes\n",
    "df_final['recency_days'] = df_final['recency_days'].astype('int64')\n",
    "df_final['purchases_quantity'] = df_final['purchases_quantity'].astype('int64')\n",
    "df_final['qt_items'] = df_final['qt_items'].astype('int64')\n",
    "df_final['qt_returns'] = df_final['qt_returns'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. **Deploy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1. **Inserting data to PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # establish connections\n",
    "# conn_string = 'postgresql://outleto_database_i6iq_user:cB48h09VeQsMHz22ScmpYurzXgjvfBKM@dpg-ce0dh92rrk09esa12060-a.oregon-postgres.render.com/outleto_database_i6iq'\n",
    "\n",
    "# db = create_engine(conn_string)\n",
    "# conn = db.connect()\n",
    "# conn1 = psycopg2.connect(\n",
    "# database=\"outleto_database_i6iq\",\n",
    "# user='outleto_database_i6iq_user',\n",
    "# password='cB48h09VeQsMHz22ScmpYurzXgjvfBKM',\n",
    "# host='dpg-ce0dh92rrk09esa12060-a.oregon-postgres.render.com',\n",
    "# port= '5432'\n",
    "# )\n",
    "\n",
    "# conn1.autocommit = True\n",
    "# cursor = conn1.cursor()\n",
    "\n",
    "# # drop table if it already exists\n",
    "# cursor.execute('drop table if exists customers')\n",
    "\n",
    "# query = \"\"\"\n",
    "#     CREATE TABLE customers (\n",
    "#         customer_id INTEGER,\n",
    "#         gross_revenue REAL,\n",
    "#         recency_days INTEGER,\n",
    "#         purchases_quantity INTEGER,\n",
    "#         qt_items INTEGER,\n",
    "#         qt_returns INTEGER, \n",
    "#         purchased_returned_diff REAL,\n",
    "#         cluster CHAR\n",
    "#     )\n",
    "# \"\"\"\n",
    "# cursor.execute(query)\n",
    "\n",
    "# conn = create_engine('postgresql://outleto_database_i6iq_user:cB48h09VeQsMHz22ScmpYurzXgjvfBKM@dpg-ce0dh92rrk09esa12060-a.oregon-postgres.render.com/outleto_database_i6iq')\n",
    "# df_final.to_sql('customers', con=conn, if_exists='replace', index=False)\n",
    "\n",
    "# conn1.commit()\n",
    "# conn1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv-cluster': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a967a499c268a8be1a4414ad2bedaa1cc2389dd3e2dec74d97f347a769603366"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
